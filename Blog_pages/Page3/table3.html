<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>table : 2</title>
    <link rel="stylesheet" href="table3.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@1,300&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Condensed:wght@400&display=swap" rel="stylesheet">
    <!-- CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi" crossorigin="anonymous">

</head>

<body>
    <div class="container">
        <nav class="navigation-bar">
            <div class="main-class-navigation-flx-clss">
                <div id="oodles-brand-logo-header-main-cls">
                    <img src="../../oodles_brand_logo.png" alt="ooodles/brand/logo" width="30%">
                </div>
                <div class="container-nav-items-main">
                    <div class="mobile-nav">
                        <button class="mobile-btn" onclick="toggleMenu(1)">Menu</button>
                    </div>
                    <ul class="nav" id="main-nav">
                        <li class="close-item">
                            <button class="mobile-btn" onclick="toggleMenu(0)">Close &times;</button>
                        </li>
                        <li class="navigation-bar-items">
                            <a href="../../index.html" class="nav-link-items">Home</a>
                        </li>
                        <!-- <li class="navigation-bar-items">
                    <a href="#!" class="nav-link">
                      Courses <i class="fa fa-caret-down"></i>
                    </a>
                    <ul class="dropDown-menu level-1">
                      <li class="dropDown-item">
                        <a href="#!" class="dropDown-link">
                          Physics
                        </a>
                        
                      </li>
                      <li class="dropDown-item">
                        <a href="#!" class="dropDown-link">
                          Chemistry 
                        </a>
                        
                      </li>
                      <li class="dropDown-item">
                        <a href="#!" class="dropDown-link">Maths</a>
                      </li>
                    </ul>
                  </li> -->
                        <li class="navigation-bar-items">
                            <a href="../Team/Team.html" class="nav-link-items">Team</a>
                        </li>
                        <li class="navigation-bar-items">
                            <a href="#!" class="nav-link-items">Blog</a>
                        </li>
                        <!-- <li class="navigation-bar-items">
                    <a href="#!" class="nav-link">Contact</a>
                  </li> -->
                        <div id="get-started-button-main-class">
                            <a href="#" class="btn-get-start black">Get Started</a>
                        </div>
                    </ul>
                </div>
            </div>
        </nav>
    </div>



    <div id="table-content-main-class">
        <div id="blog-table-second-container-mn-class">
            <h5>Bias in Recommender Systems</h5>
        </div>
        <div id="table-content-card-main-class">


            <div id="tbl-list-img-head-mn-cls">
                <div class="table-img-head-clss">
                    <img src="../../list.png" alt="list-oodles">
                </div>
                <div class="table-head-mn-class-oodles">
                    <h5>tables of content</h5>
                </div>
            </div>
            <div id="mn-cls-for-table-head-btm-para">
                <a href="#Intro"><li>- Introduction  </li></a>
                <a href="#model1"><li>- User Interaction Adds Bias</li></a>
            </div>
            <div id="mn-cls-btm-lst-mn-class">
                <ol>
                    <a href="#fststep">
                        <li>Selection Bias</li>
                    </a>
                    <a href="#second-step">
                        <li> Exposure Bias</li>
                    </a>
                    <a href="#third-main-class">
                        <li>Conformity Bias</li>
                    </a>
                    <a href="#forth-main-class">
                        <li>Position Bias</li>
                    </a>
                    
                </ol>
                
            </div>
            <div id="mn-cls-for-table-head-btm-para" class="second-table-content-mn-class">
                <a href="#biase-data-2"><li>- Biases Present in Data </li></a>
                <a href="#how-to-solve"><li>- How to solve it?</li></a>
            </div>
            <div id="mn-cls-btm-lst-mn-class">
                <ol>
                    <a href="#biasfst">
                        <li>Propensity Score</li>
                    </a>
                    <a href="#biasscnd">
                        <li>Data Imputation</li>
                    </a>
                    <a href="#biasthrd">
                        <li>Modeling Popularity Influence</li>
                    </a>
                    <a href="#biasfrth">
                        <li>Sampling</li>
                    </a>
                    <a href="#biasffth">
                        <li>Click Models</li>
                    </a>
                    <a href="#biasxth">
                        <li>Regularization</li>
                    </a>
                    <a href="#biassvth">
                        <li>Rebalancing</li>
                    </a>
                    <a href="#biaseth">
                        <li>Adversarial Learning</li>
                    </a>
                    <a href="#biasnnth">
                        <li>Reinforcement Learning</li>
                    </a>
                   
                    
                </ol>
        </div>
        <div id="mn-cls-for-table-head-btm-para" class="second-table-content-mn-class">
            <a href="#conclusion"><li>- Conclusion</li></a>

        </div>
        </div>
        <div id="table-crd-btm-man-application-cls">
            <div id="table-crd-text-btm-cls">
                <p id="Intro">Modern-day web systems rely on user feedback (such as click activity or ratings) to build ML models to personalize recommendations. Such recommender systems form the core of several popular applications that recommend short videos (Instagram, TikTok, YouTube), timeline feeds (Twitter, Facebook), the next product to buy (Amazon, Ebay), etc.  </p>


            </div>
        </div>
        <div id="table-link-mn-class">
           
            <div id="table-image-bottom-paragraph-main-class">
                <p id="model1"><b>User Interaction Adds Bias</b></p>
                <p>Model retraining is the process of updating the data of any deployed model. The updated data is used to retrain the model and keep the model up to date. It ensures the accuracy rate and precision rate of the model are not compromised, and quality service is ensured. However, model retraining doesn't change the model's algorithm; it simply means updating the model's dataset to get accurate results even after a long time.
                </p>
            </div>

            <div id="steps-main-class-table">
                <p id="fststep"><b>1. Selection bias:</b> It arises due to the user’s self-selection behavior. For example, a user might rate a movie they like but rarely rate a movie they dislike. Training on such a dataset is challenging since high ratings account for the majority of observed ratings. These ratings are not a representative sample of all ratings; that is, the rating data is often missing not at random, thus incorporating a selection bias. The following figure from a rating survey highlights this issue, where users tend to only rate items that they like.
                    </p>

            </div>
            <div id="table-ml-main-img-class">
                <img src="./img1.png" alt="">
            </div>

            <div id="steps-main-class-table">
                <p id="second-step"><b>2. Exposure bias: </b>  The user is likely to watch a recommended video, even if it is not the best fit. This action is then taken as positive feedback by the system to recommend similar videos further, resulting in exposure bias in the data. 
                    </p>

            </div>
            
            <div id="steps-main-class-table">
                <p id="third-main-class"><b>3. Conformity bias:</b> A user may be influenced by public opinions and might not select their true preferences. This results in conformity bias.
                    </p>

            </div>



            <div id="steps-main-class-table">
                <p id="forth-main-class"><b>4. Position bias:</b> The user will likely watch one of the top 5 videos in response to a YouTube search. The bias arising due to the display position of the item is referred to as Position bias.
                    
                    </p>

            </div>
            
            <div id="table-image-bottom-paragraph-main-class">
                <p id="biase-data-2"><b>User Interaction Adds Bias</b></p>
                <p>The above biases are due to user behaviors, but there are biases present in the training data itself, such as the <b>popularity bias</b>, where some items are more popular than others and hence generate more feedback from users, eventually making recommendations biased towards them. 
                    <br><br>
                    Another bias generally seen in training data is <b>Unfairness</b>, which is due to the recommender system unfairly discriminating against certain groups of individuals, such as on the basis of gender, race, age, wealth, education level, etc. For example, in the context of job recommendation, it has been found that women see fewer advertisements about high-paying jobs due to gender imbalance in training data. 
                    <br><br>
                    Finally, due to the <b>Feedback Loop</b> in recommender systems, these biases only intensify over time, resulting in a “the rich get richer” effect. This is because a bias in data results in a bias in recommendations, which in turn impacts the exposure and selection of users, causing further biases in the data.
                </p>
            </div>
            <div id="table-ml-main-img-class">
                <img src="./img2.png" alt="">
            </div>
            <div id="steps-main-class-table">
                <p> (Title) An illustration of how popularity bias can exacerbate through feedback</p>

            </div>
            <div id="steps-main-class-table">
                <p>
                    Feedback loops are detected by measuring the diversity of popularity of items in the system. The popularity of all items generally follows a long-tail distribution, where most of the items are not interacted with at all. In general, the more diversity of outputs of the recommender systems (aka the long-tail distribution has a greater entropy), the less the system suffers from degenerate feedback loops. On the other hand, low scores imply a homogeneous system that suffers from popularity bias. 
                    </p>

            </div>

            <div id="table-image-bottom-paragraph-main-class">
                <p id="how-to-solve"><b>How to solve it?</b></p>
                <p>Due to the above biases, the data observed by a recommendation system used to personalize users’ preferences might deviate from reflecting users’ true preferences. 
                    The ubiquity of such systems in modern web companies has resulted in a growing interest in ameliorating bias in recommender systems. The following methods have gained significant interest due to their effectiveness in reducing bias.
                    
                </p>
            </div>

            <div id="steps-main-class-table">
                <p id="biasfst"><b>1. Propensity Score:</b> Propensity scores can be calculated and fed back into the training loop to reduce bias due to the user's observation of items. The propensity score models the probability of exposure to a specific item. These probabilities are then later used to reweigh the interactions while retraining. For example, if the probability of exposure to an item is high, it can be downweighed during training to reduce the effects of its exposure on the user. 
                    </p>

            </div>
       
            <div id="steps-main-class-table">
                <p id="biasscnd"><b>2. Data Imputation:</b> Selection bias happens due to missing data (e.g., users prefer to give high ratings than low ratings). Data imputation can be used to solve for selection bias by imputing the missing entries with pseudo-labels.
                    </p>

            </div>

            <div id="steps-main-class-table">
                <p id="biasthrd"><b>3. Modeling Popularity Influence: </b>Conformity bias occurs when users are influenced by popular opinion. One way to reduce its effect is to disentangle the effect caused by conformity by leveraging the average popularity of the item and offsetting it from the.
                    </p>

            </div>

            <div id="steps-main-class-table">
                <p id="biasfrth"><b>4. Sampling:</b> Apart from propensity-score based weighing, sampling of items while retraining can be used to address exposure bias. The sampling determines which items to choose, and its distribution can be used as item confidence weights. Thus, it can limit the effect due to exposure by choosing an appropriate sampling distribution.
                    </p>

            </div>

            <div id="steps-main-class-table">
                <p id="biasffth"><b>5. Click Models: </b> Position bias, where the item is more likely to be interacted with due to its display position, can be mitigated using click models. The idea is to model the 
                    </p>

            </div>

            <div id="steps-main-class-table">
                <p id="biassxth"><b>6. Regularization:</b> Regularization can be used to mitigate popularity bias and unfairness in recommender systems. It has been shown that introducing suitable regularization terms can result in more balanced recommendation results.
                    </p>

            </div>

            <div id="steps-main-class-table">
                <p id="biassvth"><b>7. Rebalancing:</b> A simple method to tackle unfairness is to rebalance the training dataset with specific fairness objectives like gender parity. This can be done using re-labeling the positive labels in favor of the minority class or resampling the training data to balance the size of both classes.
                    </p>

            </div>

            <div id="steps-main-class-table">
                <p id="biaseth"><b>8. Adversarial Learning:</b> Apart from regularization, adversarial learning can be employed to ameliorate popularity bias and unfairness. The basic idea is to introduce an adversary whose aim is to confuse the recommender by giving a signal to recommend more niche items. Eventually, the adversary learns the implicit association between popular and niche items while the recommender captures niche items that correlate with the user’s history, resulting in more long-tail item recommendations. 
                    </p>

            </div>
            <div id="steps-main-class-table">
                <p id="biasnnth"><b>9. Reinforcement Learning:</b> Finally, reinforcement learning can counter the loop amplification effect of biases by deploying a more intelligent strategy to balance exploitation and exploration adaptively. However, such methods require the policy to be deployed online to be evaluated.
                    </p>

            </div>

            <div id="table-ml-main-img-class">
                <img src="./img3.png" alt="">
            </div>
       
            <div id="table-crd-btm-man-application-cls">
                <div id="table-crd-text-btm-cls">
                    <p id="conclusion">We at Oodles AI are passionate about solving this problem statement for our users so that they can go another day without worrying about the efficacy of their models. So if you are a ML Practitioner, Data Scientist or Product Lead, we would love to hear from you. So, do reach out to us at <a href="#">hello@oodles.ai</a> and sign up for the beta access to stay in the loop   </p>
    
    
                </div>
            </div>
        </div>
         
    <hr>
    <!-- FOOTER FOOTER FOOTER FOOTER FOOTER FOOTER FOOTER FOTTER FOTEER FOTTER FOTTER FOOTER FOOTER -->
    <footer>
        <div id="footer-main-class">
            <div id="join-beta-waitlist-header-main-cls">
                <h5>Join the Beta Waitlist</h5>
            </div>
            <div id="join-beta-subscribe-button-main-cls">
                <form action="" class="form-main-clss">
                    <input type="email" name="email" id="Subscribe-bx-footr-odles" placeholder="eg., abc@example.com"
                        required>
                    <input type="submit" value="JOIN" id="subscribe-btn-footer-stl-cls"
                        onclick="alert('We will release the closed Beta by Mid-October. Stay tuned!')">
                </form>
            </div>
            <div id="footer-brand-name-main-class">
                <h5>We will release the closed Beta by Mid-October. Stay tuned!</h5>
            </div>
            <div id="footer-bottom-copyright-main-class">
                <h5>&#169;2022 by Oodles.ai</h5>
            </div>
        </div>
    </footer>
</body>

</html>